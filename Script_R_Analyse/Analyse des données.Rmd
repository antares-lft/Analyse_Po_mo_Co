---
title: "Analyse dN_dS et pN_pS"
output: html_document
date: "2025-06-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
# Load necessary libraries
library(tidyverse)

# Define the folder path containing the CSV files
folder_path <- "/home/alafitte/Internship/Rapport de stage/Données"

# Generate full file paths for 20 CSV files named resultats_final_01.csv to resultats_final_20.csv
file_paths <- file.path(folder_path, sprintf("resultats_final_%02d.csv", 1:20))

# Read, process and aggregate data from all files
data_by_species <- file_paths %>%
  # Assign names to each file for easier debugging/tracking
  set_names(sprintf("file_%02d", 1:20)) %>%
  # Read each file and bind rows into a single data frame
  map_dfr(~ {
    df <- read_csv(.x, col_types = cols())
    
    # Keep only rows where all required columns for the calculation are non-missing
    # Note: We do NOT filter 'taille_pop' or 'moyenne_points' here yet
    df <- df %>%
      filter(!is.na(dN), !is.na(dS), !is.na(Nw_sum.1), !is.na(Sw_sum.1), !is.na(branch_length))
    
    # Calculate 'moyenne_points' (mean points) line by line using the given formula:
    # (dN/dS) divided by (Nw_sum.1 / Sw_sum.1)
    # Then select relevant columns for further analysis
    df %>%
      mutate(moyenne_points = (dN / dS) / (Nw_sum.1 / Sw_sum.1)) %>%
      select(species, taille_pop, branch_length, moyenne_points)
  }) %>%
  # Now filter out invalid population sizes and infinite or NA moyenne_points values
  filter(!is.na(taille_pop), taille_pop > 0, is.finite(moyenne_points)) %>%
  # Group by species and population size to aggregate values
  group_by(species, taille_pop) %>%
  summarise(
    moyenne_points = mean(moyenne_points, na.rm = TRUE),            # Mean of moyenne_points per species and pop size
    moyenne_branch_length = mean(branch_length, na.rm = TRUE),       # Mean branch length per group
    .groups = "drop"                                                 # Ungroup after summarise
  ) %>%
  # Add log10 transformed columns for population size and branch length for modeling and plotting
  mutate(
    log10_taille_pop = log10(taille_pop),
    log10_branch_length = log10(moyenne_branch_length)
  )

# Fit a linear regression model predicting moyenne_points from log10 population size
model <- lm(moyenne_points ~ log10_taille_pop, data = data_by_species)

# Summarize the model results
model_summary <- summary(model)
r_squared <- round(model_summary$r.squared, 3)
p_value <- signif(coef(model_summary)[2, 4], 3)

# Create a scatter plot with regression line
ggplot(data_by_species, aes(x = log10_taille_pop, y = moyenne_points, color = log10_branch_length)) +
  geom_point(size = 3) +  # Points sized for clarity
  geom_smooth(method = "lm", se = TRUE, color = "black", fill = "lightgray") +  # Linear regression fit with confidence interval
  scale_color_viridis_c(option = "plasma", name = "Branch length (log10)") +   # Color scale for branch length (log scale)
  annotate("text",
           x = max(data_by_species$log10_taille_pop),
           y = max(data_by_species$moyenne_points),
           label = paste0("R² = ", r_squared),
           hjust = 1, size = 4.5) +    # Add R-squared annotation top right
  annotate("text",
           x = max(data_by_species$log10_taille_pop),
           y = max(data_by_species$moyenne_points) - 0.1,
           label = paste0("p = ", p_value),
           hjust = 1, size = 4.5) +    # Add p-value annotation just below R²
  theme_minimal() +                 # Clean minimal theme
  labs(
    title = "dN/dS ~ log10(Population size)",
    x = "Population size (log10)",
    y = "Mean dN/dS"
  )

You can also embed plots, for example:


# Load required libraries
library(tidyverse)

# Define the directory path where CSV files are located
folder_path <- "/home/alafitte/Internship/Rapport de stage/Données"

# Generate file paths for 20 CSV files named resultats_final_01.csv to resultats_final_20.csv
file_paths <- file.path(folder_path, sprintf("resultats_final_%02d.csv", 1:20))

# Read, process, and aggregate data from all files into one data frame
data_by_species <- file_paths %>%
  # Assign names to each file for better traceability
  set_names(sprintf("file_%02d", 1:20)) %>%
  # Read each CSV and combine them into one dataframe
  map_dfr(~ {
    df <- read_csv(.x, col_types = cols())
    
    # Keep only rows with no missing values in the necessary columns for calculation
    # Note: population size (taille_pop) and moyenne_points filtering will be done after calculation
    df <- df %>%
      filter(!is.na(Pin), !is.na(Pis), !is.na(Nw_sum), !is.na(Sw_sum), !is.na(branch_length))
    
    # Calculate 'moyenne_points' as (Pin / Pis) divided by (Nw_sum / Sw_sum)
    # Select relevant columns for the analysis
    df %>%
      mutate(moyenne_points = (Pin / Pis) / (Nw_sum / Sw_sum)) %>%
      select(species, taille_pop, branch_length, moyenne_points)
  }) %>%
  # Filter out rows with missing or invalid population sizes and infinite/NA moyenne_points after calculation
  filter(!is.na(taille_pop), taille_pop > 0, is.finite(moyenne_points)) %>%  
  # Group data by species and population size for aggregation
  group_by(species, taille_pop) %>%
  summarise(
    moyenne_points = mean(moyenne_points, na.rm = TRUE),          # Average moyenne_points per group
    moyenne_branch_length = mean(branch_length, na.rm = TRUE),     # Average branch length per group
    .groups = "drop"                                               # Ungroup after summarizing
  ) %>%
  # Add log10-transformed columns for population size and branch length for modeling and plotting
  mutate(
    log10_taille_pop = log10(taille_pop),
    log10_branch_length = log10(moyenne_branch_length)
  )

# Fit a linear regression model predicting moyenne_points from log10 population size
model <- lm(moyenne_points ~ log10_taille_pop, data = data_by_species)

# Get a summary of the model to extract R² and p-value
model_summary <- summary(model)
r_squared <- round(model_summary$r.squared, 3)
p_value <- signif(coef(model_summary)[2, 4], 3)

# Create a scatter plot showing moyenne_points vs log10 population size colored by log10 branch length
ggplot(data_by_species, aes(x = log10_taille_pop, y = moyenne_points, color = log10_branch_length)) +
  geom_point(size = 3) +  # Plot points
  geom_smooth(method = "lm", se = TRUE, color = "black", fill = "lightgray") +  # Add regression line with confidence interval
  scale_color_viridis_c(option = "plasma", name = "Branch length (log10)") +   # Color scale for branch length
  annotate("text",
           x = max(data_by_species$log10_taille_pop),
           y = max(data_by_species$moyenne_points),
           label = paste0("R² = ", r_squared),
           hjust = 1, size = 4.5) +    # Annotate R² at top-right corner
  annotate("text",
           x = max(data_by_species$log10_taille_pop),
           y = max(data_by_species$moyenne_points) - 0.1,
           label = paste0("p = ", p_value),
           hjust = 1, size = 4.5) +    # Annotate p-value just below R²
  theme_minimal() +                 # Use a clean minimal theme
  labs(
    title = "pN/pS ~ log10(Population size)",
    x = "Population size (log10)",
    y = "Mean pN/pS"
  )


```{r pressure, echo=FALSE}

```
```{r cars }

```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
```{r pressure, echo=FALSE}
# Load required libraries
library(tidyverse)

# Define the folder path containing the CSV files
folder_path <- "/home/alafitte/Internship/Rapport de stage/Données"

# Generate full file paths for the 20 CSV files named resultats_final_01.csv to resultats_final_20.csv
file_paths <- file.path(folder_path, sprintf("resultats_final_%02d.csv", 1:20))

# Read each CSV into a list of data frames and name each element for easy reference
data_list <- file_paths %>%
  lapply(read_csv, col_types = cols()) %>%
  set_names(sprintf("file_%02d", 1:20))

# Combine all data frames into one big data frame, adding a column to identify the source file
data <- bind_rows(
  lapply(seq_along(data_list), function(i) {
    df <- data_list[[i]]
    df$file <- paste0("file_", i)  # Add file identifier column
    df
  })
)

# Data cleaning and transformation:
data <- data %>%
  # Ensure selected columns are numeric
  mutate(across(c(dN_dS, taille_pop, Pis, branch_length), as.numeric)) %>%
  # Filter out rows where Pis or dN_dS are zero or negative (to avoid issues with log10)
  filter(Pis > 0, dN_dS > 0) %>%
  # Create log10-transformed columns for Pis and dN/dS
  mutate(
    log10_Pis = log10(Pis),
    log10_dN_dS = log10(dN_dS)
  ) %>%
  # Remove rows with NA, infinite or NaN values in the log-transformed columns, which would break the regression
  filter(
    !is.na(log10_Pis), !is.infinite(log10_Pis), !is.nan(log10_Pis),
    !is.na(log10_dN_dS), !is.infinite(log10_dN_dS), !is.nan(log10_dN_dS)
  )

# === Linear regression: model log10(dN/dS) as a function of log10(Pis) ===
model <- lm(log10_dN_dS ~ log10_Pis, data = data)

# Extract the summary and coefficients
model_summary <- summary(model)
coefficients <- model_summary$coefficients

# Extract R-squared and p-value for the slope coefficient, rounded for readability
r_squared <- round(model_summary$r.squared, 3)
p_value <- signif(coefficients[2, 4], 3)

# Prepare labels for plot annotation
r2_label <- paste0("R² = ", r_squared)
pval_label <- paste0("p = ", p_value)

# === Plot with color gradient representing branch length ===
ggplot(data, aes(x = log10_Pis, y = log10_dN_dS, color = branch_length)) +
  geom_point(alpha = 0.8, size = 2.5) +                    # Scatter plot points
  geom_smooth(method = "lm", se = TRUE, color = "black", fill = "grey80") +  # Regression line with confidence interval
  annotate("text", 
           x = min(data$log10_Pis, na.rm = TRUE), 
           y = max(data$log10_dN_dS, na.rm = TRUE), 
           label = r2_label, hjust = 0, size = 4.5) +       # Annotate R² on top-left
  annotate("text", 
           x = min(data$log10_Pis, na.rm = TRUE), 
           y = max(data$log10_dN_dS, na.rm = TRUE) - 0.15, 
           label = pval_label, hjust = 0, size = 4.5) +     # Annotate p-value just below R²
  scale_color_viridis_c(option = "plasma", name = "Branch length") +  # Color scale for branch length
  theme_minimal() +
  labs(
    title = "log(dN/dS) ~ log(pS)",
    x = "log10(pS)",
    y = "log10(dN/dS)"
  )
```



```{r cars }
# Load required libraries
library(tidyverse)

# Define the folder path containing the CSV files
folder_path <- "/home/alafitte/Internship/Rapport de stage/Données"

# Generate full file paths for the 20 CSV files named resultats_final_01.csv to resultats_final_20.csv
file_paths <- file.path(folder_path, sprintf("resultats_final_%02d.csv", 1:20))

# Read each CSV into a list of data frames, naming each element for easier tracking
data_list <- file_paths %>%
  lapply(read_csv, col_types = cols()) %>%
  set_names(sprintf("file_%02d", 1:20))

# Combine all data frames into a single data frame,
# adding a column indicating the source file for each row
data <- bind_rows(
  lapply(seq_along(data_list), function(i) {
    df <- data_list[[i]]
    df$file <- paste0("file_", i)  # Add source file identifier
    df
  })
)

# Data cleaning and transformation:
data <- data %>%
  # Ensure selected columns are numeric
  mutate(across(c(pN_pS, taille_pop, Pis, branch_length), as.numeric)) %>%
  # Filter out rows where Pis or pN/pS are zero or negative (to avoid log10 issues)
  filter(Pis > 0, pN_pS > 0) %>%
  # Create log10-transformed variables for Pis and pN/pS
  mutate(
    log10_Pis = log10(Pis),
    log10_pN_pS = log10(pN_pS)
  )

# === Linear regression: model log10(pN/pS) as a function of log10(Pis) ===
model <- lm(log10_pN_pS ~ log10_Pis, data = data)

# Summarize the model to extract coefficients and statistics
model_summary <- summary(model)
coefficients <- model_summary$coefficients

# Extract R-squared and p-value for the slope term, rounding for clarity
r_squared <- round(model_summary$r.squared, 3)
p_value <- signif(coefficients[2, 4], 3)

# Prepare labels for plot annotations
r2_label <- paste0("R² = ", r_squared)
pval_label <- paste0("p = ", p_value)

# === Plot the data with a color gradient based on branch length ===
ggplot(data, aes(x = log10_Pis, y = log10_pN_pS, color = branch_length)) +
  geom_point(alpha = 0.8, size = 2.5) +  # Scatter plot with semi-transparent points
  geom_smooth(method = "lm", se = TRUE, color = "black", fill = "grey80") +  # Linear regression line with confidence interval
  annotate("text", 
           x = min(data$log10_Pis, na.rm = TRUE), 
           y = max(data$log10_pN_pS, na.rm = TRUE), 
           label = r2_label, hjust = 0, size = 4.5) +  # Add R² label top-left
  annotate("text", 
           x = min(data$log10_Pis, na.rm = TRUE), 
           y = max(data$log10_pN_pS, na.rm = TRUE) - 0.15, 
           label = pval_label, hjust = 0, size = 4.5) +  # Add p-value label just below R²
  scale_color_viridis_c(option = "plasma", name = "Branch length") +  # Color scale for branch length
  theme_minimal() +
  labs(
    title = "log(pN/pS) ~ log(pS)",
    x = "log10(pS)",
    y = "log10(pN/pS)"
  )


```
